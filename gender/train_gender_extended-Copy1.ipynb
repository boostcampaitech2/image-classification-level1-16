{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7996b754-3951-46d9-ac17-2288a59718d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataset import get_gender_dataset\n",
    "from trainer import Trainer\n",
    "from inference import create_label, sum_label\n",
    "from loss import LabelSmoothing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4530c32d-f8a3-492c-bf37-9b1da4b70778",
   "metadata": {},
   "outputs": [],
   "source": [
    "## seeds\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4ce54d-ecc0-460a-b6b1-3b8107507726",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameters\n",
    "\n",
    "model_name = 'vit_base_patch16_224'\n",
    "batch_size = 128\n",
    "lr = 0.00006\n",
    "num_epoch = 40\n",
    "target = 'gender'\n",
    "split = 20\n",
    "\n",
    "df_ff_path = f'/opt/ml/code/df/df_ff.csv'\n",
    "df_train_path = f'/opt/ml/code/df/df_mask_gender_train_{split}.csv'\n",
    "df_valid_path = f'/opt/ml/code/df/df_mask_gender_valid_{split}.csv'\n",
    "#df_test_path = '/opt/ml/input/data/eval/info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdc9923-a57c-4eb5-8f20-493ccea36164",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare dataset\n",
    "\n",
    "df_ff = pd.read_csv(df_ff_path)\n",
    "df_train = pd.read_csv(df_train_path)\n",
    "df_valid = pd.read_csv(df_valid_path)\n",
    "\n",
    "train_dataset, valid_dataset = get_gender_dataset(df_ff, df_train, df_valid, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbd6554-31d9-44d5-9aea-e73fac2b3592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : [10633 14630]\n"
     ]
    }
   ],
   "source": [
    "## prepare sampler\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "weight = df_train[target].value_counts().sort_index().to_numpy() + df_ff.gender.value_counts().sort_index().to_numpy() \n",
    "print('count :', weight)\n",
    "weight = 1. / weight\n",
    "samples_weight = np.array([weight[t] for t in df_ff[target]] + [weight[t] for t in df_train[target]])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31b51ae-c253-478d-a2a1-2c673a6ad4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare Dataloader\n",
    "\n",
    "dataloaders = {'train' : DataLoader(train_dataset, batch_size=batch_size, num_workers=3, drop_last=True, sampler=sampler),\n",
    "               'valid' : DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=3, drop_last=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec6b85-d8be-4b23-91a4-9db6abdeef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check input train batch\n",
    "a = iter(dataloaders['train'])\n",
    "from utils import imshow\n",
    "for i in range(4):\n",
    "    batch = next(a)\n",
    "imshow(batch[0])\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d52762-416a-414b-b9df-65b1c55d84a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit_base_patch16_224 ready\n"
     ]
    }
   ],
   "source": [
    "## prepare model\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "if model_name.startswith('efficientnet'):\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    model = EfficientNet.from_pretrained(model_name, num_classes=2)\n",
    "elif model_name.startswith('vit'):\n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=2)\n",
    "else:\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))\n",
    "    \n",
    "\n",
    "print(model_name, 'ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb8b32-c1ef-4c78-8563-29c5ef1bae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.head.requires_grad = True\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059f364-7d17-4a16-ba17-79a2e387bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothing(0.05)\n",
    "optimizer = optim.Adam(model.head.parameters(), lr=lr)\n",
    "lr_scheduler = None #optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15], gamma = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f72af9d-da9b-4ef9-b6cc-0d4ab85c685c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e00a5-6372-454e-bb6f-336cdba0a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer('/opt/ml/code/save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec43c8e-ec7d-4346-8a24-5d13ea71d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "## resume\n",
    "# model.load_state_dict(torch.load('/opt/ml/code/save/label/effnet_test018.pt'))\n",
    "\n",
    "# change lr manually:\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17cd26e-04c3-47af-ab0b-7b20a22ea6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model, dataloaders, criterion, optimizer, device, num_epochs=num_epoch, scheduler=lr_scheduler,\n",
    "              sub_dir='gender_extened', save_name='vit_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96fd83-6ed3-425b-a166-1767d9ef8a6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiment Logs\n",
    "\n",
    "---\n",
    "\n",
    "## Gender(Extended) Experiment Logs\n",
    "\n",
    "---\n",
    "\n",
    "1. model=eff b0, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=224, loss_fn=LS(0.05), split 20%\n",
    "    * epoch 53)\n",
    "      - train Loss: 0.1424 Acc: 0.9878 F1: 0.9877829872469728\n",
    "      - valid Loss: 0.1475 Acc: 0.9897 F1: 0.9891505862856257\n",
    "      - fixed valid        Acc: 0.9915 F1: 0.9911055553512997   \n",
    "\n",
    "2. model=eff b3, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=300, loss_fn=LS(0.05), fixed, split 20%\n",
    "    * epoch 06)\n",
    "      - train Loss: 0.1799 Acc: 0.9688 F1: 0.968828211679331\n",
    "      - valid Loss: 0.1401 Acc: 0.9926 F1: 0.9922154582288432     \n",
    "\n",
    "3. model=eff b3, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=300, loss_fn=LS(0.1), fixed, split 20%\n",
    "    * epoch 06)\n",
    "      - train Loss: 0.1799 Acc: 0.9688 F1: 0.968828211679331\n",
    "      - valid Loss: 0.1401 Acc: 0.9926 F1: 0.9922154582288432 \n",
    "\n",
    "---\n",
    "\n",
    "## Gender Experiment Logs\n",
    "\n",
    "---\n",
    "\n",
    "1. model=eff b0, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=224, loss_fn=LS(0.05), split 20%\n",
    "    * epoch 18)\n",
    "      - train Loss: 0.1446 Acc: 0.9881 F1: 0.9880777974235919\n",
    "      - valid Loss: 0.1551 Acc: 0.9854 F1: 0.9846651730146876\n",
    "        \n",
    "2. model=eff b0, optimizer=Adam, lr=0.0003, bs=64, augment=randaug+cutout, inputsize=224, loss_fn=LS(0.05), split 20%\n",
    "    * epoch 15)\n",
    "      - train Loss: 0.1371 Acc: 0.9911 F1: 0.9911258239235885\n",
    "      - valid Loss: 0.1574 Acc: 0.9868 F1: 0.9860680087572518\n",
    "---\n",
    "3. model=eff b0, optimizer=Adam, lr=0.0003, bs=64, augment=randaug+cutout, inputsize=224, crop=224, loss_fn=LS(0.05), split 20%\n",
    "    * epoch 09)\n",
    "      - train Loss: 0.1574 Acc: 0.9799 F1: 0.9798725637365424\n",
    "      - valid Loss: 0.1556 Acc: 0.9820 F1: 0.9810713788113145\n",
    "---\n",
    "4. model=eff b0, optimizer=Adam, lr=0.0003, bs=64, augment=randaug+cutout, inputsize=224, crop=280, loss_fn=LS(0.05), split 20%\n",
    "    * epoch 09)\n",
    "      - train Loss: 0.1574 Acc: 0.9799 F1: 0.9798725637365424\n",
    "      - valid Loss: 0.1556 Acc: 0.9820 F1: 0.9810713788113145\n",
    "\n",
    "### loss function test\n",
    "\n",
    "---\n",
    "\n",
    "1. eff b0, lr=0.00006, bs=64, randaug+cutout, inputsize=224, loss_fn=CE, WeightedSampler, split 25%, optimizer=Adam\n",
    "   * epoch 18)\n",
    "     - train Loss: 0.0991 Acc: 0.9655 F1: 0.9654261306812848\n",
    "     - valid Loss: 0.0980 Acc: 0.9778 F1: 0.9772288369633227  \n",
    "  * before first patience\n",
    "\n",
    "---\n",
    "\n",
    "2. eff b0, lr=0.00006, bs=64, randaug+cutout, inputsize=224, loss_fn=LS(0.05), WeightedSampler, split 25%, optimizer=Adam\n",
    "    * epoch 21)\n",
    "     - train Loss: 0.3310 Acc: 0.9638 F1: 0.963728513759618\n",
    "     - valid Loss: 0.3071 Acc: 0.9786 F1: 0.9791634664746235 \n",
    "\n",
    "---\n",
    "\n",
    "3. eff b0, lr=0.00006, bs=64, randaug+cutout, inputsize=224, loss_fn=F1_Loss, split 25%, optimizer=Adam\n",
    "   * epoch 13)\n",
    "     - train Loss: 0.0710 Acc: 0.9584 F1: 0.9476713834498373\n",
    "     - valid Loss: 0.0403 Acc: 0.9765 F1: 0.9748789208889367\n",
    "   * epoch 3)\n",
    "     - train Loss: 0.0594 Acc: 0.9655 F1: 0.9555452013464937\n",
    "     - valid Loss: 0.0369 Acc: 0.9782 F1: 0.9776768545260203\n",
    "\n",
    "---\n",
    "\n",
    "### split ratio test\n",
    "\n",
    "---\n",
    "\n",
    "4. model=eff b0, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=224, loss_fn=LS(0.05), split 15%\n",
    "    * epoch 21)\n",
    "      - train Loss: 0.3381 Acc: 0.9597 F1: 0.9597144587078792\n",
    "      - valid Loss: 0.2948 Acc: 0.9852 F1: 0.982564296238198\n",
    "      \n",
    "---\n",
    "\n",
    "5. model=eff b0, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=224, loss_fn=LS(0.05), split 20%\n",
    "    * epoch 27)\n",
    "      - train Loss: 0.3211 Acc: 0.9668 F1: 0.9668728849468181\n",
    "      - valid Loss: 0.2878 Acc: 0.9854 F1: 0.9842203787970396\n",
    "      \n",
    "---\n",
    "\n",
    "6. model=eff b0, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=224, loss_fn=LS(0.05), split 25%\n",
    "    * epoch 22)\n",
    "      - train Loss: 0.3321 Acc: 0.9639 F1: 0.9638739223128628\n",
    "      - valid Loss: 0.2910 Acc: 0.9829 F1: 0.9792575649184908\n",
    "      \n",
    "---\n",
    "\n",
    "7. model=eff b0, optimizer=Adam, lr=0.00006, bs=64, augment=randaug+cutout, inputsize=224, loss_fn=LS(0.05), split 30%\n",
    "    * epoch 29)\n",
    "      - train Loss: 0.3171 Acc: 0.9686 F1: 0.9685813478405522\n",
    "      - valid Loss: 0.3047 Acc: 0.9772 F1: 0.9764751322879572"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295c4fc-4288-4144-93e9-21e291038455",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5030a4-82cb-404a-9db1-69db51493035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "model.load_state_dict(torch.load('/opt/ml/code/save/gender_extened/log2.pt'))\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "wrong = []\n",
    "prob = []\n",
    "\n",
    "for inputs, labels in dataloaders['train']:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        pr = softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred.extend(preds.tolist())\n",
    "        wrong_idx = np.nonzero(y_true != y_pred)\n",
    "        prob.append(pr[wrong_idx].cpu().numpy())\n",
    "        for p, t, inp in zip(preds, labels, inputs):\n",
    "            if p.item() != t.item():\n",
    "                wrong.append((inp.cpu().numpy(), p.item(), t.item()))\n",
    "                \n",
    "prob = np.concatenate(prob)\n",
    "mtx = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(mtx)\n",
    "print(f1_score(y_true, y_pred, average='macro'), accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54fc1a-7e17-4b8f-b089-f596baa71718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_ = list(range(2))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = ax.imshow(mtx, cmap='Blues', vmax=100, vmin=-20)\n",
    "\n",
    "ax.set_xticks(np.arange(len(label_)))\n",
    "ax.set_yticks(np.arange(len(label_)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(label_)\n",
    "ax.set_yticklabels(label_)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(label_)):\n",
    "    for j in range(len(label_)):\n",
    "        if mtx[i, j]:\n",
    "            text = ax.text(j, i, mtx[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\", size=10)\n",
    "ax.set_xlabel('Prediction')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_title(\"Confusion mtx\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029d90d-cb67-4e77-9484-091c7e35a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterator = iter(wrong)\n",
    "\n",
    "label = [\"Male\", \"Female\"]\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075c3d9-0b2c-4b47-87c7-fe9ae73ed049",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10,10))\n",
    "for ax in axes.flatten():\n",
    "    img, p, t = next(iterator)\n",
    "    img = img.transpose((1, 2, 0))\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f't : {label[t]}\\np : {label[p]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eaf34c-187e-4ec4-b138-7e7175aec242",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4adaff3-e3c4-4276-83eb-4bed95f1c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_label(df):\n",
    "    \n",
    "    def _label(row):\n",
    "        return row['age'] + 3*row['label']# + 6*row['mask']\n",
    "\n",
    "    df['ans'] = df.apply(_label, axis=1)\n",
    "    return df[['ImageID', 'ans']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd079ed1-90da-49f2-befe-cdde1ce57ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inference\n",
    "\n",
    "# model.load_state_dict(torch.load('/opt/ml/code/save/best_log2.pt'))\n",
    "# df_submit = create_label(model, test_dataloader, df_test.copy(), device, target='label')\n",
    "\n",
    "# model = EfficientNet.from_pretrained(model_name, num_classes=3).to(device)\n",
    "# model.load_state_dict(torch.load('/opt/ml/code/save/age/extended_far_best.pt'))\n",
    "# df_submit = create_label(model, test_dataloader, df_submit, device, target='age')\n",
    "\n",
    "# model.load_state_dict(torch.load('/opt/ml/code/save/mask/6e5_9987.pt'))\n",
    "# df_submit = create_label(model, test_dataloader, df_submit, device, target='mask')\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, 2).cuda()\n",
    "# model.load_state_dict(torch.load('/opt/ml/code/save/gender/6e5_9851.pt'))\n",
    "# df_submit = create_label(model, test_dataloader, df_submit, device, target='gender')\n",
    "\n",
    "\n",
    "# df_submit = sum_label(df_submit)\n",
    "# df_submit\n",
    "\n",
    "\n",
    "df_submit.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18999aea-a13b-45e3-bcd6-8973cb9aabfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
