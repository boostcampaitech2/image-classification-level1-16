{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "# 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4939c8c4-8e55-491f-bf3c-a061b3e2dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    " \n",
    "from dataset import MaskBaseDataset, BaseAugmentation, MaskSplitByProfileDataset\n",
    "from datadoubling import DataDoubling\n",
    "import train as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-organizer",
   "metadata": {},
   "source": [
    "# 1. Data Path Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e4f96c-b773-4518-8bfe-4f5e580c1ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/code\n",
      "/opt/ml/input/data/train/images\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/opt/ml/input/data/eval' #test데이터 경로\n",
    "train_dir = '/opt/ml/input/data/train' #train데이터 경로\n",
    "\n",
    "train_csv = pd.read_csv(os.path.join(train_dir, 'train.csv'))\n",
    "train_data_images = os.path.join(train_dir, 'images')\n",
    "\n",
    "print(os.getcwd())\n",
    "print(train_data_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1587dc-6380-4bf3-bc2c-7ca3a3c81200",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/opt/ml/input/data/train/images2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-304a1bc85ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataDoubling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/datadoubling.py\u001b[0m in \u001b[0;36mcopy_dir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/opt/ml/input/data/train/images2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'copy complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n\u001b[0m\u001b[1;32m    555\u001b[0m                      \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                      \u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mignored_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirs_exist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0muse_srcentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcopy2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcopy_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/opt/ml/input/data/train/images2'"
     ]
    }
   ],
   "source": [
    "instance = DataDoubling(train_data_images)\n",
    "instance.copy_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32cc4aaa-eaeb-41ae-bad2-a85e2051b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doubling completed!\n"
     ]
    }
   ],
   "source": [
    "copy_instance = DataDoubling(os.path.join(train_dir, 'images2'))\n",
    "copy_instance.data_doubling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a8b056-de09-46c0-88dd-2185d8b991de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from efficientnet_pytorch) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16445 sha256=3a36ca4f03eb197f41a0a333626138610b27229b787fb2cc44f1d93554e0d262\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-channels",
   "metadata": {},
   "source": [
    "# 2. Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951e515d-9862-4df1-ba43-23bb2e47da61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_data_images = os.path.join(train_dir, 'images2')\n",
    "total_dataset = MaskBaseDataset(train_data_images)\n",
    "\n",
    "inject_transform = BaseAugmentation(224,total_dataset.mean, total_dataset.std )\n",
    "\n",
    "total_dataset.set_transform(inject_transform)\n",
    "\n",
    "#print(total_dataset[3])\n",
    "#print(total_dataset.calc_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "# 3. Data Split to (Train, Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3425b0aa-b6a1-45eb-af7e-1cdf633026ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train[1] data : (tensor([[[ 1.3777,  1.2288,  1.5597,  ..., -0.5086, -0.5252, -0.5583],\n",
      "         [ 1.3942,  1.2453,  1.5597,  ..., -0.4094, -0.4259, -0.4425],\n",
      "         [ 1.4273,  1.2453,  1.5431,  ..., -0.3928, -0.3928, -0.4094],\n",
      "         ...,\n",
      "         [ 1.0302,  0.8316,  0.5834,  ..., -1.2036, -1.1540, -1.1043],\n",
      "         [ 1.2619,  1.2453,  1.2122,  ..., -1.1705, -1.0878, -1.0712],\n",
      "         [ 0.9475,  1.1129,  1.1957,  ..., -1.1540, -1.0547, -1.0547]],\n",
      "\n",
      "        [[ 1.2619,  1.1190,  1.4365,  ...,  1.1349,  1.0714,  1.0396],\n",
      "         [ 1.2778,  1.1349,  1.4365,  ...,  1.2143,  1.1666,  1.1349],\n",
      "         [ 1.3095,  1.1349,  1.4207,  ...,  1.1984,  1.1825,  1.1666],\n",
      "         ...,\n",
      "         [ 1.1825,  0.9920,  0.7856,  ..., -0.9767, -0.9291, -0.8815],\n",
      "         [ 1.3730,  1.3571,  1.3413,  ..., -0.9450, -0.8656, -0.8497],\n",
      "         [ 1.0555,  1.1984,  1.2936,  ..., -0.9291, -0.8338, -0.8338]],\n",
      "\n",
      "        [[ 1.3208,  1.1773,  1.4643,  ...,  0.9701,  0.9223,  0.8904],\n",
      "         [ 1.3368,  1.1933,  1.4643,  ...,  1.0498,  1.0179,  0.9861],\n",
      "         [ 1.3686,  1.1933,  1.4643,  ...,  1.0498,  1.0339,  1.0179],\n",
      "         ...,\n",
      "         [ 1.3527,  1.1773,  0.9701,  ..., -0.9110, -0.8631, -0.8153],\n",
      "         [ 1.4802,  1.4802,  1.4643,  ..., -0.8791, -0.7994, -0.7834],\n",
      "         [ 1.1295,  1.2889,  1.4005,  ..., -0.8631, -0.7675, -0.7675]]]), 8), 15575\n",
      "valid[1] data : (tensor([[[ 1.3446,  1.3446,  1.3446,  ...,  1.3115,  1.2949,  1.2949],\n",
      "         [ 1.3446,  1.3446,  1.3446,  ...,  1.3280,  1.3115,  1.2949],\n",
      "         [ 1.3611,  1.3611,  1.3611,  ...,  1.3280,  1.3280,  1.3115],\n",
      "         ...,\n",
      "         [-2.1468, -2.1468, -2.1137,  ..., -0.7072, -0.1612, -0.1281],\n",
      "         [-2.1468, -2.1468, -2.1137,  ..., -1.0216, -0.2274, -0.1446],\n",
      "         [-2.1468, -2.1468, -2.1137,  ..., -1.2532, -0.2935, -0.1612]],\n",
      "\n",
      "        [[ 1.4524,  1.4524,  1.4524,  ...,  1.4048,  1.3889,  1.3889],\n",
      "         [ 1.4524,  1.4524,  1.4524,  ...,  1.4207,  1.4048,  1.3889],\n",
      "         [ 1.4683,  1.4683,  1.4683,  ...,  1.4207,  1.4207,  1.4048],\n",
      "         ...,\n",
      "         [-1.6912, -1.6912, -1.6594,  ..., -0.4528, -0.0083, -0.0241],\n",
      "         [-1.6912, -1.6912, -1.6594,  ..., -0.7545, -0.0400, -0.0083],\n",
      "         [-1.6912, -1.6912, -1.6594,  ..., -0.9767, -0.1035, -0.0241]],\n",
      "\n",
      "        [[ 1.5281,  1.5281,  1.5281,  ...,  1.5281,  1.5121,  1.5121],\n",
      "         [ 1.5281,  1.5281,  1.5281,  ...,  1.5440,  1.5281,  1.5121],\n",
      "         [ 1.5440,  1.5440,  1.5440,  ...,  1.5440,  1.5440,  1.5281],\n",
      "         ...,\n",
      "         [-1.5964, -1.5964, -1.5646,  ..., -0.3211,  0.1412,  0.1412],\n",
      "         [-1.5964, -1.5964, -1.5646,  ..., -0.6240,  0.0933,  0.1412],\n",
      "         [-1.5964, -1.5964, -1.5646,  ..., -0.8472,  0.0296,  0.1252]]]), 7), 3325\n"
     ]
    }
   ],
   "source": [
    "split_object  = MaskSplitByProfileDataset(train_data_images)\n",
    "\n",
    "inject_transform = BaseAugmentation(224,split_object.mean, split_object.std )\n",
    "split_object.set_transform(inject_transform)\n",
    "train_dataset , valid_dataset = split_object.split_dataset()\n",
    "\n",
    "print('train[1] data : {}, {}'.format(train_dataset[1], len(train_dataset)))\n",
    "print('valid[1] data : {}, {}'.format(valid_dataset[1], len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af935e5e-69aa-4120-9c9d-39e31e2e2e9a",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638e46d3-ce24-4b16-ac25-c84edf405eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augmentation='CustomAugmentation', batch_size=64, criterion='cross_entropy', data_dir='/opt/ml/input/data/train/images', dataset='MaskSplitByProfileDataset', epochs=21, log_interval=20, lr=6e-05, lr_decay_step=20, model='MyModel', model1='MyModel1', model2='MyModel2', model3='MyModel3', model_dir='./model', name='exp', optimizer='Adam', resize=[224, 224], seed=42, val_ratio=0.2, valid_batch_size=64)\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch[0/21](20/241) || training loss 7.085 || training accuracy 0.08% || lr 6e-05\n",
      "Epoch[0/21](40/241) || training loss 6.339 || training accuracy 1.88% || lr 6e-05\n",
      "Epoch[0/21](60/241) || training loss 5.356 || training accuracy 12.11% || lr 6e-05\n",
      "Epoch[0/21](80/241) || training loss 4.156 || training accuracy 30.55% || lr 6e-05\n",
      "Epoch[0/21](100/241) || training loss 2.984 || training accuracy 45.55% || lr 6e-05\n",
      "Epoch[0/21](120/241) || training loss 2.274 || training accuracy 48.98% || lr 6e-05\n",
      "Epoch[0/21](140/241) || training loss 1.878 || training accuracy 53.91% || lr 6e-05\n",
      "Epoch[0/21](160/241) || training loss 1.62 || training accuracy 57.73% || lr 6e-05\n",
      "Epoch[0/21](180/241) || training loss 1.517 || training accuracy 58.59% || lr 6e-05\n",
      "Epoch[0/21](200/241) || training loss 1.347 || training accuracy 62.03% || lr 6e-05\n",
      "Epoch[0/21](220/241) || training loss 1.25 || training accuracy 62.81% || lr 6e-05\n",
      "Epoch[0/21](240/241) || training loss 1.184 || training accuracy 64.53% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 56.67%! saving the best model..\n",
      "[Val] acc : 56.67%, loss:  1.4 || best acc : 56.67%, best loss:  1.4\n",
      "\n",
      "Epoch[1/21](20/241) || training loss 1.037 || training accuracy 68.28% || lr 6e-05\n",
      "Epoch[1/21](40/241) || training loss 0.9857 || training accuracy 69.61% || lr 6e-05\n",
      "Epoch[1/21](60/241) || training loss 0.946 || training accuracy 69.84% || lr 6e-05\n",
      "Epoch[1/21](80/241) || training loss 0.9779 || training accuracy 69.38% || lr 6e-05\n",
      "Epoch[1/21](100/241) || training loss 0.9001 || training accuracy 71.25% || lr 6e-05\n",
      "Epoch[1/21](120/241) || training loss 0.8482 || training accuracy 73.20% || lr 6e-05\n",
      "Epoch[1/21](140/241) || training loss 0.8173 || training accuracy 74.22% || lr 6e-05\n",
      "Epoch[1/21](160/241) || training loss 0.8069 || training accuracy 74.38% || lr 6e-05\n",
      "Epoch[1/21](180/241) || training loss 0.8069 || training accuracy 73.20% || lr 6e-05\n",
      "Epoch[1/21](200/241) || training loss 0.7328 || training accuracy 77.11% || lr 6e-05\n",
      "Epoch[1/21](220/241) || training loss 0.7103 || training accuracy 77.03% || lr 6e-05\n",
      "Epoch[1/21](240/241) || training loss 0.6778 || training accuracy 77.42% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 76.79%! saving the best model..\n",
      "[Val] acc : 76.79%, loss: 0.68 || best acc : 76.79%, best loss: 0.68\n",
      "\n",
      "Epoch[2/21](20/241) || training loss 0.6458 || training accuracy 79.45% || lr 6e-05\n",
      "Epoch[2/21](40/241) || training loss 0.6571 || training accuracy 79.06% || lr 6e-05\n",
      "Epoch[2/21](60/241) || training loss 0.6796 || training accuracy 76.17% || lr 6e-05\n",
      "Epoch[2/21](80/241) || training loss 0.6412 || training accuracy 78.20% || lr 6e-05\n",
      "Epoch[2/21](100/241) || training loss 0.658 || training accuracy 78.36% || lr 6e-05\n",
      "Epoch[2/21](120/241) || training loss 0.6258 || training accuracy 79.61% || lr 6e-05\n",
      "Epoch[2/21](140/241) || training loss 0.5811 || training accuracy 80.47% || lr 6e-05\n",
      "Epoch[2/21](160/241) || training loss 0.5827 || training accuracy 81.33% || lr 6e-05\n",
      "Epoch[2/21](180/241) || training loss 0.5784 || training accuracy 81.09% || lr 6e-05\n",
      "Epoch[2/21](200/241) || training loss 0.5891 || training accuracy 79.45% || lr 6e-05\n",
      "Epoch[2/21](220/241) || training loss 0.5869 || training accuracy 80.78% || lr 6e-05\n",
      "Epoch[2/21](240/241) || training loss 0.5767 || training accuracy 81.02% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 81.26%! saving the best model..\n",
      "[Val] acc : 81.26%, loss: 0.54 || best acc : 81.26%, best loss: 0.54\n",
      "\n",
      "Epoch[3/21](20/241) || training loss 0.4936 || training accuracy 84.53% || lr 6e-05\n",
      "Epoch[3/21](40/241) || training loss 0.5178 || training accuracy 81.88% || lr 6e-05\n",
      "Epoch[3/21](60/241) || training loss 0.5482 || training accuracy 81.56% || lr 6e-05\n",
      "Epoch[3/21](80/241) || training loss 0.5038 || training accuracy 81.72% || lr 6e-05\n",
      "Epoch[3/21](100/241) || training loss 0.4825 || training accuracy 83.20% || lr 6e-05\n",
      "Epoch[3/21](120/241) || training loss 0.4572 || training accuracy 84.38% || lr 6e-05\n",
      "Epoch[3/21](140/241) || training loss 0.493 || training accuracy 82.66% || lr 6e-05\n",
      "Epoch[3/21](160/241) || training loss 0.4786 || training accuracy 83.28% || lr 6e-05\n",
      "Epoch[3/21](180/241) || training loss 0.4631 || training accuracy 83.98% || lr 6e-05\n",
      "Epoch[3/21](200/241) || training loss 0.5293 || training accuracy 81.48% || lr 6e-05\n",
      "Epoch[3/21](220/241) || training loss 0.4336 || training accuracy 85.78% || lr 6e-05\n",
      "Epoch[3/21](240/241) || training loss 0.4543 || training accuracy 84.61% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 82.08%! saving the best model..\n",
      "[Val] acc : 82.08%, loss:  0.5 || best acc : 82.08%, best loss:  0.5\n",
      "\n",
      "Epoch[4/21](20/241) || training loss 0.4069 || training accuracy 85.39% || lr 6e-05\n",
      "Epoch[4/21](40/241) || training loss 0.4383 || training accuracy 85.16% || lr 6e-05\n",
      "Epoch[4/21](60/241) || training loss 0.4461 || training accuracy 84.45% || lr 6e-05\n",
      "Epoch[4/21](80/241) || training loss 0.4162 || training accuracy 84.45% || lr 6e-05\n",
      "Epoch[4/21](100/241) || training loss 0.3994 || training accuracy 85.86% || lr 6e-05\n",
      "Epoch[4/21](120/241) || training loss 0.3864 || training accuracy 87.19% || lr 6e-05\n",
      "Epoch[4/21](140/241) || training loss 0.4076 || training accuracy 86.02% || lr 6e-05\n",
      "Epoch[4/21](160/241) || training loss 0.3841 || training accuracy 86.88% || lr 6e-05\n",
      "Epoch[4/21](180/241) || training loss 0.4151 || training accuracy 85.94% || lr 6e-05\n",
      "Epoch[4/21](200/241) || training loss 0.4247 || training accuracy 85.23% || lr 6e-05\n",
      "Epoch[4/21](220/241) || training loss 0.4354 || training accuracy 85.39% || lr 6e-05\n",
      "Epoch[4/21](240/241) || training loss 0.4003 || training accuracy 86.25% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 83.90%! saving the best model..\n",
      "[Val] acc : 83.90%, loss: 0.45 || best acc : 83.90%, best loss: 0.45\n",
      "\n",
      "Epoch[5/21](20/241) || training loss 0.3357 || training accuracy 87.97% || lr 6e-05\n",
      "Epoch[5/21](40/241) || training loss 0.3519 || training accuracy 86.56% || lr 6e-05\n",
      "Epoch[5/21](60/241) || training loss 0.3548 || training accuracy 87.50% || lr 6e-05\n",
      "Epoch[5/21](80/241) || training loss 0.3701 || training accuracy 86.95% || lr 6e-05\n",
      "Epoch[5/21](100/241) || training loss 0.3603 || training accuracy 86.72% || lr 6e-05\n",
      "Epoch[5/21](120/241) || training loss 0.3911 || training accuracy 86.95% || lr 6e-05\n",
      "Epoch[5/21](140/241) || training loss 0.3726 || training accuracy 85.16% || lr 6e-05\n",
      "Epoch[5/21](160/241) || training loss 0.3681 || training accuracy 86.48% || lr 6e-05\n",
      "Epoch[5/21](180/241) || training loss 0.3704 || training accuracy 86.88% || lr 6e-05\n",
      "Epoch[5/21](200/241) || training loss 0.3266 || training accuracy 87.89% || lr 6e-05\n",
      "Epoch[5/21](220/241) || training loss 0.3591 || training accuracy 87.50% || lr 6e-05\n",
      "Epoch[5/21](240/241) || training loss 0.3534 || training accuracy 88.59% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 84.31%! saving the best model..\n",
      "[Val] acc : 84.31%, loss: 0.44 || best acc : 84.31%, best loss: 0.44\n",
      "\n",
      "Epoch[6/21](20/241) || training loss 0.2751 || training accuracy 89.14% || lr 6e-05\n",
      "Epoch[6/21](40/241) || training loss 0.3338 || training accuracy 88.44% || lr 6e-05\n",
      "Epoch[6/21](60/241) || training loss 0.3083 || training accuracy 89.22% || lr 6e-05\n",
      "Epoch[6/21](80/241) || training loss 0.3064 || training accuracy 89.22% || lr 6e-05\n",
      "Epoch[6/21](100/241) || training loss 0.2878 || training accuracy 88.91% || lr 6e-05\n",
      "Epoch[6/21](120/241) || training loss 0.3018 || training accuracy 89.22% || lr 6e-05\n",
      "Epoch[6/21](140/241) || training loss 0.292 || training accuracy 89.53% || lr 6e-05\n",
      "Epoch[6/21](160/241) || training loss 0.3001 || training accuracy 88.91% || lr 6e-05\n",
      "Epoch[6/21](180/241) || training loss 0.3139 || training accuracy 90.16% || lr 6e-05\n",
      "Epoch[6/21](200/241) || training loss 0.3273 || training accuracy 89.14% || lr 6e-05\n",
      "Epoch[6/21](220/241) || training loss 0.3279 || training accuracy 88.12% || lr 6e-05\n",
      "Epoch[6/21](240/241) || training loss 0.2743 || training accuracy 89.92% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 84.84%! saving the best model..\n",
      "[Val] acc : 84.84%, loss: 0.43 || best acc : 84.84%, best loss: 0.43\n",
      "\n",
      "Epoch[7/21](20/241) || training loss 0.2922 || training accuracy 90.08% || lr 6e-05\n",
      "Epoch[7/21](40/241) || training loss 0.286 || training accuracy 90.00% || lr 6e-05\n",
      "Epoch[7/21](60/241) || training loss 0.2715 || training accuracy 89.84% || lr 6e-05\n",
      "Epoch[7/21](80/241) || training loss 0.2444 || training accuracy 91.41% || lr 6e-05\n",
      "Epoch[7/21](100/241) || training loss 0.2562 || training accuracy 91.17% || lr 6e-05\n",
      "Epoch[7/21](120/241) || training loss 0.2641 || training accuracy 90.70% || lr 6e-05\n",
      "Epoch[7/21](140/241) || training loss 0.2684 || training accuracy 90.62% || lr 6e-05\n",
      "Epoch[7/21](160/241) || training loss 0.2617 || training accuracy 90.55% || lr 6e-05\n",
      "Epoch[7/21](180/241) || training loss 0.2411 || training accuracy 91.17% || lr 6e-05\n",
      "Epoch[7/21](200/241) || training loss 0.2643 || training accuracy 90.39% || lr 6e-05\n",
      "Epoch[7/21](220/241) || training loss 0.2454 || training accuracy 90.70% || lr 6e-05\n",
      "Epoch[7/21](240/241) || training loss 0.2545 || training accuracy 90.62% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.02%, loss: 0.44 || best acc : 84.84%, best loss: 0.43\n",
      "\n",
      "Epoch[8/21](20/241) || training loss 0.2618 || training accuracy 91.02% || lr 6e-05\n",
      "Epoch[8/21](40/241) || training loss 0.2274 || training accuracy 91.48% || lr 6e-05\n",
      "Epoch[8/21](60/241) || training loss 0.2546 || training accuracy 90.94% || lr 6e-05\n",
      "Epoch[8/21](80/241) || training loss 0.2242 || training accuracy 93.28% || lr 6e-05\n",
      "Epoch[8/21](100/241) || training loss 0.2589 || training accuracy 90.31% || lr 6e-05\n",
      "Epoch[8/21](120/241) || training loss 0.2356 || training accuracy 90.78% || lr 6e-05\n",
      "Epoch[8/21](140/241) || training loss 0.2584 || training accuracy 91.33% || lr 6e-05\n",
      "Epoch[8/21](160/241) || training loss 0.227 || training accuracy 91.02% || lr 6e-05\n",
      "Epoch[8/21](180/241) || training loss 0.2264 || training accuracy 91.95% || lr 6e-05\n",
      "Epoch[8/21](200/241) || training loss 0.2279 || training accuracy 92.81% || lr 6e-05\n",
      "Epoch[8/21](220/241) || training loss 0.2146 || training accuracy 91.56% || lr 6e-05\n",
      "Epoch[8/21](240/241) || training loss 0.2411 || training accuracy 91.95% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 85.07%! saving the best model..\n",
      "[Val] acc : 85.07%, loss: 0.43 || best acc : 85.07%, best loss: 0.43\n",
      "\n",
      "Epoch[9/21](20/241) || training loss 0.2073 || training accuracy 93.36% || lr 6e-05\n",
      "Epoch[9/21](40/241) || training loss 0.2095 || training accuracy 92.89% || lr 6e-05\n",
      "Epoch[9/21](60/241) || training loss 0.2267 || training accuracy 92.11% || lr 6e-05\n",
      "Epoch[9/21](80/241) || training loss 0.1802 || training accuracy 93.36% || lr 6e-05\n",
      "Epoch[9/21](100/241) || training loss 0.1797 || training accuracy 93.91% || lr 6e-05\n",
      "Epoch[9/21](120/241) || training loss 0.2045 || training accuracy 92.81% || lr 6e-05\n",
      "Epoch[9/21](140/241) || training loss 0.2107 || training accuracy 92.58% || lr 6e-05\n",
      "Epoch[9/21](160/241) || training loss 0.2412 || training accuracy 92.34% || lr 6e-05\n",
      "Epoch[9/21](180/241) || training loss 0.1946 || training accuracy 91.95% || lr 6e-05\n",
      "Epoch[9/21](200/241) || training loss 0.1863 || training accuracy 92.97% || lr 6e-05\n",
      "Epoch[9/21](220/241) || training loss 0.2107 || training accuracy 92.97% || lr 6e-05\n",
      "Epoch[9/21](240/241) || training loss 0.1848 || training accuracy 93.12% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.01%, loss: 0.45 || best acc : 85.07%, best loss: 0.43\n",
      "\n",
      "Epoch[10/21](20/241) || training loss 0.1882 || training accuracy 93.44% || lr 6e-05\n",
      "Epoch[10/21](40/241) || training loss 0.1772 || training accuracy 93.52% || lr 6e-05\n",
      "Epoch[10/21](60/241) || training loss 0.1804 || training accuracy 94.45% || lr 6e-05\n",
      "Epoch[10/21](80/241) || training loss 0.1851 || training accuracy 93.59% || lr 6e-05\n",
      "Epoch[10/21](100/241) || training loss 0.1798 || training accuracy 93.44% || lr 6e-05\n",
      "Epoch[10/21](120/241) || training loss 0.1557 || training accuracy 94.92% || lr 6e-05\n",
      "Epoch[10/21](140/241) || training loss 0.1541 || training accuracy 94.06% || lr 6e-05\n",
      "Epoch[10/21](160/241) || training loss 0.1827 || training accuracy 93.67% || lr 6e-05\n",
      "Epoch[10/21](180/241) || training loss 0.1789 || training accuracy 93.36% || lr 6e-05\n",
      "Epoch[10/21](200/241) || training loss 0.1671 || training accuracy 93.98% || lr 6e-05\n",
      "Epoch[10/21](220/241) || training loss 0.1745 || training accuracy 93.59% || lr 6e-05\n",
      "Epoch[10/21](240/241) || training loss 0.198 || training accuracy 92.66% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.95%, loss: 0.47 || best acc : 85.07%, best loss: 0.43\n",
      "\n",
      "Epoch[11/21](20/241) || training loss 0.1313 || training accuracy 96.33% || lr 6e-05\n",
      "Epoch[11/21](40/241) || training loss 0.1579 || training accuracy 94.45% || lr 6e-05\n",
      "Epoch[11/21](60/241) || training loss 0.1406 || training accuracy 95.70% || lr 6e-05\n",
      "Epoch[11/21](80/241) || training loss 0.1559 || training accuracy 94.22% || lr 6e-05\n",
      "Epoch[11/21](100/241) || training loss 0.1513 || training accuracy 95.16% || lr 6e-05\n",
      "Epoch[11/21](120/241) || training loss 0.1538 || training accuracy 94.53% || lr 6e-05\n",
      "Epoch[11/21](140/241) || training loss 0.1617 || training accuracy 94.45% || lr 6e-05\n",
      "Epoch[11/21](160/241) || training loss 0.1618 || training accuracy 94.38% || lr 6e-05\n",
      "Epoch[11/21](180/241) || training loss 0.1473 || training accuracy 94.53% || lr 6e-05\n",
      "Epoch[11/21](200/241) || training loss 0.1529 || training accuracy 94.84% || lr 6e-05\n",
      "Epoch[11/21](220/241) || training loss 0.1702 || training accuracy 94.22% || lr 6e-05\n",
      "Epoch[11/21](240/241) || training loss 0.1689 || training accuracy 93.98% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 85.33%! saving the best model..\n",
      "[Val] acc : 85.33%, loss: 0.49 || best acc : 85.33%, best loss: 0.43\n",
      "\n",
      "Epoch[12/21](20/241) || training loss 0.1314 || training accuracy 95.39% || lr 6e-05\n",
      "Epoch[12/21](40/241) || training loss 0.13 || training accuracy 95.78% || lr 6e-05\n",
      "Epoch[12/21](60/241) || training loss 0.1178 || training accuracy 95.86% || lr 6e-05\n",
      "Epoch[12/21](80/241) || training loss 0.1551 || training accuracy 93.83% || lr 6e-05\n",
      "Epoch[12/21](100/241) || training loss 0.1445 || training accuracy 95.39% || lr 6e-05\n",
      "Epoch[12/21](120/241) || training loss 0.139 || training accuracy 94.53% || lr 6e-05\n",
      "Epoch[12/21](140/241) || training loss 0.119 || training accuracy 96.17% || lr 6e-05\n",
      "Epoch[12/21](160/241) || training loss 0.1567 || training accuracy 94.30% || lr 6e-05\n",
      "Epoch[12/21](180/241) || training loss 0.1403 || training accuracy 94.38% || lr 6e-05\n",
      "Epoch[12/21](200/241) || training loss 0.1297 || training accuracy 95.62% || lr 6e-05\n",
      "Epoch[12/21](220/241) || training loss 0.1326 || training accuracy 95.31% || lr 6e-05\n",
      "Epoch[12/21](240/241) || training loss 0.1199 || training accuracy 95.55% || lr 6e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 85.83%! saving the best model..\n",
      "[Val] acc : 85.83%, loss: 0.48 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[13/21](20/241) || training loss 0.1067 || training accuracy 96.80% || lr 6e-05\n",
      "Epoch[13/21](40/241) || training loss 0.1255 || training accuracy 96.09% || lr 6e-05\n",
      "Epoch[13/21](60/241) || training loss 0.1097 || training accuracy 95.55% || lr 6e-05\n",
      "Epoch[13/21](80/241) || training loss 0.1012 || training accuracy 96.48% || lr 6e-05\n",
      "Epoch[13/21](100/241) || training loss 0.09632 || training accuracy 96.95% || lr 6e-05\n",
      "Epoch[13/21](120/241) || training loss 0.1008 || training accuracy 96.33% || lr 6e-05\n",
      "Epoch[13/21](140/241) || training loss 0.1005 || training accuracy 97.27% || lr 6e-05\n",
      "Epoch[13/21](160/241) || training loss 0.1167 || training accuracy 95.94% || lr 6e-05\n",
      "Epoch[13/21](180/241) || training loss 0.1192 || training accuracy 95.78% || lr 6e-05\n",
      "Epoch[13/21](200/241) || training loss 0.1343 || training accuracy 94.38% || lr 6e-05\n",
      "Epoch[13/21](220/241) || training loss 0.1236 || training accuracy 95.47% || lr 6e-05\n",
      "Epoch[13/21](240/241) || training loss 0.1276 || training accuracy 95.94% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.05%, loss: 0.53 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[14/21](20/241) || training loss 0.09943 || training accuracy 96.48% || lr 6e-05\n",
      "Epoch[14/21](40/241) || training loss 0.09742 || training accuracy 96.09% || lr 6e-05\n",
      "Epoch[14/21](60/241) || training loss 0.09821 || training accuracy 96.72% || lr 6e-05\n",
      "Epoch[14/21](80/241) || training loss 0.1191 || training accuracy 96.02% || lr 6e-05\n",
      "Epoch[14/21](100/241) || training loss 0.1131 || training accuracy 96.56% || lr 6e-05\n",
      "Epoch[14/21](120/241) || training loss 0.1007 || training accuracy 96.95% || lr 6e-05\n",
      "Epoch[14/21](140/241) || training loss 0.09884 || training accuracy 96.41% || lr 6e-05\n",
      "Epoch[14/21](160/241) || training loss 0.1089 || training accuracy 96.17% || lr 6e-05\n",
      "Epoch[14/21](180/241) || training loss 0.107 || training accuracy 96.88% || lr 6e-05\n",
      "Epoch[14/21](200/241) || training loss 0.1106 || training accuracy 95.94% || lr 6e-05\n",
      "Epoch[14/21](220/241) || training loss 0.07609 || training accuracy 97.58% || lr 6e-05\n",
      "Epoch[14/21](240/241) || training loss 0.08241 || training accuracy 97.27% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.66%, loss: 0.52 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[15/21](20/241) || training loss 0.07626 || training accuracy 97.73% || lr 6e-05\n",
      "Epoch[15/21](40/241) || training loss 0.07123 || training accuracy 97.97% || lr 6e-05\n",
      "Epoch[15/21](60/241) || training loss 0.09456 || training accuracy 96.72% || lr 6e-05\n",
      "Epoch[15/21](80/241) || training loss 0.113 || training accuracy 96.41% || lr 6e-05\n",
      "Epoch[15/21](100/241) || training loss 0.08561 || training accuracy 97.34% || lr 6e-05\n",
      "Epoch[15/21](120/241) || training loss 0.07592 || training accuracy 97.27% || lr 6e-05\n",
      "Epoch[15/21](140/241) || training loss 0.07863 || training accuracy 97.03% || lr 6e-05\n",
      "Epoch[15/21](160/241) || training loss 0.08222 || training accuracy 96.95% || lr 6e-05\n",
      "Epoch[15/21](180/241) || training loss 0.09348 || training accuracy 96.56% || lr 6e-05\n",
      "Epoch[15/21](200/241) || training loss 0.08454 || training accuracy 97.27% || lr 6e-05\n",
      "Epoch[15/21](220/241) || training loss 0.08712 || training accuracy 97.11% || lr 6e-05\n",
      "Epoch[15/21](240/241) || training loss 0.08009 || training accuracy 97.58% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.36%, loss: 0.53 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[16/21](20/241) || training loss 0.1105 || training accuracy 96.48% || lr 6e-05\n",
      "Epoch[16/21](40/241) || training loss 0.08681 || training accuracy 96.72% || lr 6e-05\n",
      "Epoch[16/21](60/241) || training loss 0.1096 || training accuracy 96.17% || lr 6e-05\n",
      "Epoch[16/21](80/241) || training loss 0.06902 || training accuracy 98.05% || lr 6e-05\n",
      "Epoch[16/21](100/241) || training loss 0.05908 || training accuracy 98.05% || lr 6e-05\n",
      "Epoch[16/21](120/241) || training loss 0.06134 || training accuracy 98.52% || lr 6e-05\n",
      "Epoch[16/21](140/241) || training loss 0.07237 || training accuracy 97.19% || lr 6e-05\n",
      "Epoch[16/21](160/241) || training loss 0.08428 || training accuracy 97.66% || lr 6e-05\n",
      "Epoch[16/21](180/241) || training loss 0.07367 || training accuracy 97.42% || lr 6e-05\n",
      "Epoch[16/21](200/241) || training loss 0.08827 || training accuracy 96.48% || lr 6e-05\n",
      "Epoch[16/21](220/241) || training loss 0.09187 || training accuracy 97.34% || lr 6e-05\n",
      "Epoch[16/21](240/241) || training loss 0.07993 || training accuracy 97.58% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.74%, loss: 0.52 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[17/21](20/241) || training loss 0.06664 || training accuracy 97.81% || lr 6e-05\n",
      "Epoch[17/21](40/241) || training loss 0.07045 || training accuracy 97.42% || lr 6e-05\n",
      "Epoch[17/21](60/241) || training loss 0.06741 || training accuracy 97.73% || lr 6e-05\n",
      "Epoch[17/21](80/241) || training loss 0.06443 || training accuracy 98.05% || lr 6e-05\n",
      "Epoch[17/21](100/241) || training loss 0.08477 || training accuracy 96.88% || lr 6e-05\n",
      "Epoch[17/21](120/241) || training loss 0.06516 || training accuracy 98.20% || lr 6e-05\n",
      "Epoch[17/21](140/241) || training loss 0.06204 || training accuracy 98.12% || lr 6e-05\n",
      "Epoch[17/21](160/241) || training loss 0.08244 || training accuracy 97.27% || lr 6e-05\n",
      "Epoch[17/21](180/241) || training loss 0.079 || training accuracy 97.58% || lr 6e-05\n",
      "Epoch[17/21](200/241) || training loss 0.08241 || training accuracy 97.50% || lr 6e-05\n",
      "Epoch[17/21](220/241) || training loss 0.05997 || training accuracy 98.12% || lr 6e-05\n",
      "Epoch[17/21](240/241) || training loss 0.06603 || training accuracy 98.05% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.77%, loss: 0.54 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[18/21](20/241) || training loss 0.08006 || training accuracy 97.66% || lr 6e-05\n",
      "Epoch[18/21](40/241) || training loss 0.06169 || training accuracy 98.20% || lr 6e-05\n",
      "Epoch[18/21](60/241) || training loss 0.06651 || training accuracy 97.97% || lr 6e-05\n",
      "Epoch[18/21](80/241) || training loss 0.06629 || training accuracy 97.34% || lr 6e-05\n",
      "Epoch[18/21](100/241) || training loss 0.06514 || training accuracy 97.81% || lr 6e-05\n",
      "Epoch[18/21](120/241) || training loss 0.07318 || training accuracy 97.34% || lr 6e-05\n",
      "Epoch[18/21](140/241) || training loss 0.0693 || training accuracy 97.97% || lr 6e-05\n",
      "Epoch[18/21](160/241) || training loss 0.05634 || training accuracy 98.12% || lr 6e-05\n",
      "Epoch[18/21](180/241) || training loss 0.0502 || training accuracy 98.28% || lr 6e-05\n",
      "Epoch[18/21](200/241) || training loss 0.06048 || training accuracy 97.89% || lr 6e-05\n",
      "Epoch[18/21](220/241) || training loss 0.0589 || training accuracy 98.05% || lr 6e-05\n",
      "Epoch[18/21](240/241) || training loss 0.06351 || training accuracy 98.28% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.51%, loss: 0.54 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[19/21](20/241) || training loss 0.05981 || training accuracy 98.05% || lr 6e-05\n",
      "Epoch[19/21](40/241) || training loss 0.05145 || training accuracy 98.20% || lr 6e-05\n",
      "Epoch[19/21](60/241) || training loss 0.06158 || training accuracy 98.12% || lr 6e-05\n",
      "Epoch[19/21](80/241) || training loss 0.05127 || training accuracy 98.59% || lr 6e-05\n",
      "Epoch[19/21](100/241) || training loss 0.0459 || training accuracy 98.67% || lr 6e-05\n",
      "Epoch[19/21](120/241) || training loss 0.05148 || training accuracy 98.44% || lr 6e-05\n",
      "Epoch[19/21](140/241) || training loss 0.05483 || training accuracy 97.89% || lr 6e-05\n",
      "Epoch[19/21](160/241) || training loss 0.06739 || training accuracy 97.81% || lr 6e-05\n",
      "Epoch[19/21](180/241) || training loss 0.0597 || training accuracy 97.58% || lr 6e-05\n",
      "Epoch[19/21](200/241) || training loss 0.07493 || training accuracy 97.34% || lr 6e-05\n",
      "Epoch[19/21](220/241) || training loss 0.05164 || training accuracy 98.44% || lr 6e-05\n",
      "Epoch[19/21](240/241) || training loss 0.05667 || training accuracy 98.44% || lr 6e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.48%, loss: 0.59 || best acc : 85.83%, best loss: 0.43\n",
      "\n",
      "Epoch[20/21](20/241) || training loss 0.05069 || training accuracy 98.12% || lr 3e-05\n",
      "Epoch[20/21](40/241) || training loss 0.05067 || training accuracy 98.44% || lr 3e-05\n",
      "Epoch[20/21](60/241) || training loss 0.05622 || training accuracy 97.97% || lr 3e-05\n",
      "Epoch[20/21](80/241) || training loss 0.05391 || training accuracy 98.52% || lr 3e-05\n",
      "Epoch[20/21](100/241) || training loss 0.06349 || training accuracy 97.66% || lr 3e-05\n",
      "Epoch[20/21](120/241) || training loss 0.03805 || training accuracy 98.44% || lr 3e-05\n",
      "Epoch[20/21](140/241) || training loss 0.06179 || training accuracy 97.66% || lr 3e-05\n",
      "Epoch[20/21](160/241) || training loss 0.05271 || training accuracy 98.05% || lr 3e-05\n",
      "Epoch[20/21](180/241) || training loss 0.03817 || training accuracy 98.83% || lr 3e-05\n",
      "Epoch[20/21](200/241) || training loss 0.04727 || training accuracy 98.59% || lr 3e-05\n",
      "Epoch[20/21](220/241) || training loss 0.05019 || training accuracy 98.59% || lr 3e-05\n",
      "Epoch[20/21](240/241) || training loss 0.04786 || training accuracy 98.28% || lr 3e-05\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 85.98%! saving the best model..\n",
      "[Val] acc : 85.98%, loss: 0.58 || best acc : 85.98%, best loss: 0.43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchensemble\n",
    "!python train.py\n",
    "#print(tr.train(train_data_images, os.path.join(os.getcwd(), 'model.py')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a217bf0f-52f4-4ec1-9d83-79e59d211af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Calculating inference results..\n",
      "Inference Done! Inference result saved at ./output/output.csv\n"
     ]
    }
   ],
   "source": [
    "!python inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9242a-798a-46b5-b51d-1cd2e4367f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluation\n",
    "\n",
    "print(os.path.join(os.getcwd(), 'output'))\n",
    "print(test_dir)\n",
    "#evaluation(test_dir, os.path.join(os.getcwd(), 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a7868-a694-482b-bfdd-dcc1d7453b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
